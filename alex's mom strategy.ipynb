{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7212f3d",
      "metadata": {},
      "source": [
        "XDDDDDDDDDDDDDDDDDDDDDDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f6269362",
      "metadata": {},
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from arch import arch_model\n",
        "from scipy.stats import rankdata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aece536",
      "metadata": {},
      "source": [
        "step 1: implement volatility model (modified GARCH)  \n",
        "  \n",
        "$\\sigma_{n}^{2} = \\gamma V_{lt} +\\alpha u_{n-1}^{2} + \\beta\\sigma_{n-1}^{2}$  \n",
        "  \n",
        "where:  \n",
        "  \n",
        "$\\sigma_{n}$ is the volatility of the market variable for day $n$ (made at the end of day $n-1$). $\\sigma_{n}^{2}$ is the variance of the market variable for day $n$  \n",
        "$\\gamma$ is the weight assigned to $V_{lt}$  \n",
        "$V_{lt}$ is the long-run average variance rate  \n",
        "$\\alpha$ is the weight assigned to $u_{n-1}^{2}$   \n",
        "$u_{n-1}$ is the percentage change in the market variable between the end of day $n-2$ and the end of day $n-1$ (the most recent daily percentage change in the market variable). $u_{n-1}^{2}$ is the squared return of the market variable between the end of day $n-2$ and the end of day $n-1$  \n",
        "\n",
        "$u_{n-1} = \\frac{S_{n-1} - S_{n-2}}{S_{n-2}}$  \n",
        "\n",
        "$S_{n-1}$ is the value of the market variable at the end of day $n-1$  \n",
        "$S_{n-2}$ is the value of the market variable at the end of day $n-2$  \n",
        "\n",
        "$\\beta$ is the weight assigned to $\\sigma_{n-1}^{2}$  \n",
        "$\\sigma_{n-1}$ is the volatility of the market variable for day $n-1$ (made at the end of day $n-2$) . $\\sigma_{n-1}^{2}$ is the variance of the market variable for day $n-1$  \n",
        "  \n",
        "since the weights must sum to unity, it follows that  \n",
        "  \n",
        "$\\gamma+\\alpha+\\beta=1$  \n",
        "  \n",
        "setting $\\omega=\\gamma V_{lt}$, the model can also be written as  \n",
        "  \n",
        "$\\sigma_{n}^{2} = \\omega +\\alpha u_{n-1}^{2} + \\beta\\sigma_{n-1}^{2}$  \n",
        "  \n",
        "we include one lag of an asymmetric shock which transforms a GARCH model into a GJR-GARCH model with variance dynamics given by  \n",
        "  \n",
        "$\\sigma^2_n   =  \\omega + \\alpha u_{n-1}^2 + \\gamma u_{n-1}^2 I_{[u_{n-1}<0]}+ \\beta \\sigma_{n-1}^2$\n",
        "\n",
        "where $I$ an indicator function that takes the value 1 when its argument is true. the log likelihood improves substantially with the introduction of an asymmetric term, and the parameter estimate is highly significant.  \n",
        "\n",
        "to improve the fit a little more, we model the volatility using absolute values rather than a variance process that evolves in squares. this process, known as a TARCH/ZARCH model is given by  \n",
        "  \n",
        "$\\sigma_n  =  \\omega + \\alpha \\left|u_{n-1}\\right| + \\gamma \\left|u_{n-1}\\right| I_{[u_{n-1}<0]}+ \\beta \\sigma_{n-1}$\n",
        "\n",
        "one final adjustment, financial returns are often heavy tailed, and a Student’s T distribution is a simple method to capture this feature. The call to arch changes the distribution from a Normal to a Students’s T."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07bb969",
      "metadata": {},
      "outputs": [],
      "source": [
        "def volatility(df):\n",
        "    # df: dataframe of price data. uses GJR-GARCH/TARCH (power=1) + t distribution.\n",
        "    df = df.copy()\n",
        "    returns = 100 * df[\"Close\"].pct_change().dropna()\n",
        "    df = df.iloc[1:].copy()\n",
        "\n",
        "    am = arch_model(returns, p=1, o=1, q=1, power=1.0, dist=\"studentst\")\n",
        "    result = am.fit()\n",
        "    df.loc[:, \"Volatility\"] = result._volatility\n",
        "    df.loc[:, \"Rolling Volatility\"] = df[\"Volatility\"].rolling(window=10).mean()\n",
        "\n",
        "    calculated = df[\"Volatility\"].mean()\n",
        "    expected = np.var(returns)\n",
        "    print(f\"percent error in volatility calculation: {(np.abs(calculated - expected) / expected) * 100}\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c10f669",
      "metadata": {},
      "source": [
        "step 2: momentum  \n",
        "don't have much to say about this it's pretty straightforward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19bd8404",
      "metadata": {},
      "outputs": [],
      "source": [
        "def absolute_momentum(df):\n",
        "    # 4 month momentum\n",
        "    df = df.copy()\n",
        "    df['Momentum'] = (df[\"Close\"] / df[\"Close\"].shift(84)) - 1\n",
        "    df.dropna()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98646a32",
      "metadata": {},
      "source": [
        "step 3: ATR Trend/Breakout system  \n",
        "produces a signal based on bands. if a given's day high is higher than the upper band, the following day the model will go long (signal = 2). if a given day's low is lower than the lower band, the following day the model will go neutral/short (signal = -2). the bands are defined by the 42-day rolling average true range, with the true range being given by  \n",
        "  \n",
        "$TR = max\\left[(H-L), \\left|H-C_{n-1}\\right|, \\left|L-C_{n-1}\\right|\\right]$  \n",
        "  \n",
        "where $H$ is the day's high, $L$ is the day's low, and $C_{n-1}$ is the previous close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d9fed82",
      "metadata": {},
      "outputs": [],
      "source": [
        "def atr_trend_breakout(df):\n",
        "    df = df.copy()\n",
        "    high = df[\"High\"]\n",
        "    low = df[\"Low\"]\n",
        "    close = df[\"Close\"]\n",
        "    tr = pd.concat([high - low, (high - close.shift(1)).abs(), (low - close.shift(1)).abs()], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(42).mean()\n",
        "    upper = high.rolling(42).max() + atr  # upper = session highs + ATR\n",
        "    lower = low.rolling(42).min() - atr\n",
        "    signal = pd.Series(0.0, index=df.index)\n",
        "    long_mask = high > upper\n",
        "    short_mask = low < lower\n",
        "    signal.loc[long_mask] = 2\n",
        "    signal.loc[short_mask] = -2\n",
        "    df['ATR Trend/Breakout'] = signal.replace(0, np.nan).ffill().fillna(0)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d678452",
      "metadata": {},
      "source": [
        "step 4: average relative correlations  \n",
        "4 months average correlation across the ETFs on daily returns. requires proper merged dataframe but thats for me to figure out later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a845a08",
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation(returns_df):\n",
        "    tickers = returns_df.columns.tolist()\n",
        "    out = pd.DataFrame(index=returns_df.index, columns=tickers, dtype=float)\n",
        "    for i in range(84, len(returns_df) + 1):\n",
        "        chunk = returns_df.iloc[i - 84:i]\n",
        "        corr = chunk.corr()\n",
        "        idx = returns_df.index[i - 1]\n",
        "        for col in tickers:\n",
        "            others = [c for c in tickers if c != col]\n",
        "            if others:\n",
        "                out.loc[idx, col] = corr.loc[col, others].mean()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84dd2ec4",
      "metadata": {},
      "source": [
        "step 5: rank the motherfuckers on each metric  \n",
        "most momentum --> rank 1, least --> rank 13  \n",
        "least volatility --> rank 1, most --> rank 13  \n",
        "least correlation --> rank 1, most --> rank 13  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc70397e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rank(momentum_series, vol_series, corr_series):\n",
        "    # Rank(M)\n",
        "    rank_m = pd.Series(rankdata(momentum_series), index=momentum_series.index)\n",
        "    # Rank(V)\n",
        "    rank_v = pd.Series(rankdata(-vol_series), index=vol_series.index)\n",
        "    # Rank(C)\n",
        "    rank_c = pd.Series(rankdata(-corr_series), index=corr_series.index)\n",
        "    return rank_m, rank_v, rank_c"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7d1235",
      "metadata": {},
      "source": [
        "step 6: rank the motherfuckers part 2 as a whole (except for cash)\n",
        "\n",
        "$Rank = w_{M}R_{M} + w_{V}R_{V} + w_{C}R_{C} - T  \n",
        "  \n",
        "where $R_{M}$, $R_{V}$, and $R_{C}$ are the rankings of momentum, volatility, and correlation,   \n",
        "$w_{m}$, $w_{V}$, and $w_{C}$ are the weights assigned to the rankings of momentum, volatility, and correlation,  \n",
        "and $T$ is the signal from the ATR Trend/Breakout System "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68f2fbf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ranked_allocation(rank_m, rank_v, rank_c):\n",
        "    tickers = [x for x in rank_m.index if x != \"SHY\"]\n",
        "    n = len(tickers)\n",
        "    total = 0.45 * (n + 1 - rank_m.reindex(tickers).fillna(0))\n",
        "    total += 0.4 * (n + 1 - rank_v.reindex(tickers).fillna(0))\n",
        "    total += 0.15 * (n + 1 - rank_c.reindex(tickers).fillna(0))\n",
        "    top = total.nsmallest(5).index.tolist()\n",
        "    return top"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5a934f",
      "metadata": {},
      "source": [
        "step 7: weight portfolio  \n",
        "classification (including the ranking above) is done on a monthly basis, taking the last value of the month. we reallocate the portfolio at this time, giving our top 5 tickers 20% of the portfolio each. however, if any of the top 5 tickers have a negative absolute momentum, we replace it's weighting with cash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de9d1bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def raam_weights(momentum_series, rank_m, rank_v, rank_c):\n",
        "    top = ranked_allocation(rank_m, rank_v, rank_c)\n",
        "    weights = {}\n",
        "    cash_weight = 0.0\n",
        "    for t in top:\n",
        "        if t in momentum_series and momentum_series[t] < 0:\n",
        "            cash_weight += 0.2\n",
        "        else:\n",
        "            weights[t] = 0.2\n",
        "    if cash_weight > 0:\n",
        "        weights[\"SHY\"] = weights.get(\"SHY\", 0) + cash_weight\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd9254a",
      "metadata": {},
      "source": [
        "tickers in our portfolio:  \n",
        "  \n",
        "**Brazilian Equities:**  \n",
        "EWZ  \n",
        "FLBR  \n",
        "EWZS  \n",
        "  \n",
        "**International Equities:**  \n",
        "EFA  \n",
        "EEM  \n",
        "  \n",
        "**Brazilian Real Estate:**  \n",
        "HGBS11  \n",
        "BTLG11  \n",
        "  \n",
        "**Brazilian Natural Resources – Commodities:**  \n",
        "BIAU39  \n",
        "BSLV39  \n",
        "BCOM39  \n",
        "  \n",
        "**Brazilian Bonds:**  \n",
        "BLTN  \n",
        "VWOB (Emerging Markets)  \n",
        "  \n",
        "**International Bonds:**  \n",
        "IGOV  \n",
        "  \n",
        "**Cash:**  \n",
        "SHY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31772911",
      "metadata": {},
      "outputs": [],
      "source": [
        "TICKERS = [\"EWZ\", \"FLBR\", \"EWZS\", \"EFA\", \"EEM\", \"HGBS11\", \"BTLG11\", \"BIAU39\", \"BSLV39\", \"BCOM39\", \"BLTN\", \"VWOB\", \"IGOV\", \"SHY\"]\n",
        "RISKY_TICKERS = TICKERS[:12]\n",
        "CASH_TICKER = \"SHY\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f2c25e",
      "metadata": {},
      "source": [
        "TODO:  \n",
        "**build backtest**  \n",
        "write paper lol  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
